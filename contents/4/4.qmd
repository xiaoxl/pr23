
## Data Aggregation and Group Operations

### split-apply-combine model

We would like to apply group operations based on the split-apply-combine model. 

- In the first stage of the process, data contained in a pandas object is *split* into groups based on one or more keys that you provide. We then use `.groupby(keys)` to perform the split step. The result is a grouped `groupby` object.
- Once this is done, a function is *applied* to each group, producing a new value. 
- Finally the results of all those function applications are combined into a result object. We may apply groupby functions directly as methods to groupby objects.The result is the combined result object.


::: {#exm-}

```{python}
import pandas as pd
df = pd.DataFrame({'key1' : ['a', 'a', 'b', 'b', 'a'],
                   'key2' : ['one', 'two', 'one', 'two', 'one'],
                   'data1' : np.random.randn(5),
                   'data2' : np.random.randn(5)})
df
```
Now we want to group `data1` in `df` by `key1`.

```{python}
grouped = df['data1'].groupby(df['key1'])
grouped
```
What we get is a groupby object and we could apply group functions to it.

The method to look at each group is `.get_group`.
```{python}
grouped.get_group('a')
```

We may directly apply some group functions to the groupby object.
```{python}
grouped.mean()
```
```{python}
grouped.size()
```

We could iterate over groups.

```{python}
for name, group in grouped:
    print('name', name)
    print('group', group)
```

We could convert the group object into list and dictionary.

```{python}
list(grouped)
```
```{python}
dict(list(grouped))
```

:::

### More aggregation functions

- `.describe()`
- `.count()`
- `.sum()`
- `.mean()`
- `.median`
- `.std()`, `.var()`
- `.min()`, `.max()`
- `.prod()`
- `first()`, `.last()`
- `.agg()`


### Some examples


::: {#exm-}
Consider the following DataFrame.

```{python}
import pandas as pd
df = pd.DataFrame({'location': ['East', 'East', 'East', 'East',
                                'West', 'West', 'West', 'West'],
                   'data': np.random.randn(8)},
                   index=['Ohio', 'New York', 'Vermont', 'Florida',
                          'Oregon', 'Nevada', 'California', 'Idaho'])
df.loc[['Vermont', 'Nevada', 'Idaho'], 'data'] = np.nan
```

We would like to fill in NA values with the mean from each group.

```{python}
df.groupby('location').apply(lambda x: x.fillna(x.mean()))
```

We could also fill in NA values with predefined values, similar to the non-groupby case.

```{python}
df.groupby('location').apply(lambda x: x.fillna({'East': 0.1,
                                                 'West': -0.5}[x.name]))
```

:::









### Essential functions
- Arithmetic and Data Alignment
Elements of the same index and columns will be computed. By default, if any entry is `nan`, the answer will be `nan`. You may use `fill_value` argument to fill the empty slots.


::: {#exm-}

```{python}
import pandas as pd
import numpy as np
df1 = pd.DataFrame(np.arange(12.).reshape((3, 4)), columns=list('abcd'))
df2 = pd.DataFrame(np.arange(20.).reshape((4, 5)), columns=list('abcde'))
df2.loc[1, 'b'] = np.nan

df1.add(df2, fill_value=0)
```

:::

Relatedly, when reindexing a Series or DataFrame, you can also specify a `fill_value`.

### Function Application and Mapping
We may apply functions to each row/column of a DataFrame. If the function is built-in function that is compatible with DataFrame, you can directly call the function that it will be applied automatically to each row/column. If it is not, we can call `apply` to get the desired result. 


::: {#exm-}

```{python}
import pandas as pd
data = pd.DataFrame(np.random.rand(4, 4),
                    index=['Ohio', 'Colorado', 'Utah', 'New York'],
                    columns=['one', 'two', 'three', 'four'])

f = lambda x: x.max() - x.min()

print(data.apply(f))
print(data.apply(f, axis='columns'))
```

:::


We can use more complicated function to get more complicated result.

::: {#exm-}

```{python}
import pandas as pd
data = pd.DataFrame(np.random.rand(4, 4),
                    index=['Ohio', 'Colorado', 'Utah', 'New York'],
                    columns=['one', 'two', 'three', 'four'])

f = lambda x: pd.Series([x.max(), x.min()], index=['max', 'min'])

print(data.apply(f))
```

:::


<!-- ### Sorting and Ranking

- `.sort_values(by=)`
- `.rank(ascending=, method=)` -->




<!-- ### Summarizing and Computing Descriptive Statistics

- `sum`, `cumsum`
- `mean`, `median`
- `.describe()`
- `.cov`, `.corr` -->




<!-- ### Reading and Writing Data in Text Format
- `read_csv`
- `read_excel`
- `df.to_csv` -->


<!-- ### Copies and views

- `inplace` -->




